{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suburban-benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\w100228\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\w100228\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\w100228\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\w100228\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-photography",
   "metadata": {},
   "source": [
    "### Loadng the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satellite-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=pd.read_json('val-data-prepared.json')\n",
    "training_data=pd.read_json('train-data-prepared.json')\n",
    "#Sample_Output_data=pd.read_json('sample-output 2.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-viewer",
   "metadata": {},
   "source": [
    "### Lowering the text in training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intelligent-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['text']=training_data['text'].apply(lambda x:x.lower())\n",
    "validation_data['text']=validation_data['text'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structural-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "#sentences=nltk.sent_tokenize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-government",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-identification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "quality-devil",
   "metadata": {},
   "source": [
    "### Function for Pre-Processing of Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surface-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363ac6f16e232a1d8e9343d975ebe10</td>\n",
       "      <td>since communism has been relegated to just a h...</td>\n",
       "      <td>0</td>\n",
       "      <td>since communism has been relegated to just a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b925ce5eeb8b690b35972abafcb7c60</td>\n",
       "      <td>can you counter that?</td>\n",
       "      <td>0</td>\n",
       "      <td>can you counter that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99977c6e63734add1c1b600be79b3342</td>\n",
       "      <td>censorship does not eliminate the censored ind...</td>\n",
       "      <td>0</td>\n",
       "      <td>censorship does not eliminate the censored ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e34d9e198bc9e12f0868793c68d32f0</td>\n",
       "      <td>without the extra population from abortions, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>without the extra population from abortions  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629d09668c3339dba831f6c81a307b0e</td>\n",
       "      <td>i can't stand it</td>\n",
       "      <td>1</td>\n",
       "      <td>i can t stand it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>452684ca088e4ab1c58d89e1a28e1ef7</td>\n",
       "      <td>it's \"true\" or not and that \"truth\" is availab...</td>\n",
       "      <td>0</td>\n",
       "      <td>it s  true  or not and that  truth  is availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>b5fa34bde09f97ab565ec1ae433d1797</td>\n",
       "      <td>and these slogans don't even denote any sense ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and these slogans don t even denote any sense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>f676671baa396678dcb3471ea67e70ed</td>\n",
       "      <td>&amp;gt;whole-bodywhile</td>\n",
       "      <td>0</td>\n",
       "      <td>gt whole bodywhile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>a4e0fa2814bb40ae76750ea1597084de</td>\n",
       "      <td>that the majority of them are affected negativ...</td>\n",
       "      <td>1</td>\n",
       "      <td>that the majority of them are affected negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>5472aeb15e476c1542ca23ecd9c6e511</td>\n",
       "      <td>and just trying to be romantic with women, ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>and just trying to be romantic with women  ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0     1363ac6f16e232a1d8e9343d975ebe10   \n",
       "1     6b925ce5eeb8b690b35972abafcb7c60   \n",
       "2     99977c6e63734add1c1b600be79b3342   \n",
       "3     7e34d9e198bc9e12f0868793c68d32f0   \n",
       "4     629d09668c3339dba831f6c81a307b0e   \n",
       "...                                ...   \n",
       "2614  452684ca088e4ab1c58d89e1a28e1ef7   \n",
       "2615  b5fa34bde09f97ab565ec1ae433d1797   \n",
       "2616  f676671baa396678dcb3471ea67e70ed   \n",
       "2617  a4e0fa2814bb40ae76750ea1597084de   \n",
       "2618  5472aeb15e476c1542ca23ecd9c6e511   \n",
       "\n",
       "                                                   text  label  \\\n",
       "0     since communism has been relegated to just a h...      0   \n",
       "1                                 can you counter that?      0   \n",
       "2     censorship does not eliminate the censored ind...      0   \n",
       "3     without the extra population from abortions, h...      0   \n",
       "4                                      i can't stand it      1   \n",
       "...                                                 ...    ...   \n",
       "2614  it's \"true\" or not and that \"truth\" is availab...      0   \n",
       "2615  and these slogans don't even denote any sense ...      0   \n",
       "2616                               &gt;whole-bodywhile       0   \n",
       "2617  that the majority of them are affected negativ...      1   \n",
       "2618  and just trying to be romantic with women, ass...      0   \n",
       "\n",
       "                                            Clean_words  \n",
       "0     since communism has been relegated to just a h...  \n",
       "1                                 can you counter that   \n",
       "2     censorship does not eliminate the censored ind...  \n",
       "3     without the extra population from abortions  h...  \n",
       "4                                      i can t stand it  \n",
       "...                                                 ...  \n",
       "2614  it s  true  or not and that  truth  is availab...  \n",
       "2615  and these slogans don t even denote any sense ...  \n",
       "2616                                 gt whole bodywhile  \n",
       "2617  that the majority of them are affected negativ...  \n",
       "2618  and just trying to be romantic with women  ass...  \n",
       "\n",
       "[2619 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_words(text):\n",
    "    corpus=[]\n",
    "    for filter_words in text.split():\n",
    "        words=re.sub('[^A-Za-z0-9]+',' ',filter_words)\n",
    "        corpus.append(words)\n",
    "    corpus=' '.join(corpus)\n",
    "    return corpus.lower()\n",
    "        \n",
    "\n",
    "#training_data['Clean_words'] = training_data['text'].apply(clean_text)\n",
    "#training_data['Clean_words'] = training_data['text'].apply(clean_text1)\n",
    "training_data['Clean_words'] = training_data['text'].apply(clean_words)\n",
    "\n",
    "\n",
    "training_data\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token=\"The tall and handsome guy\"\n",
    "#tokens=word_tokenize(token)\n",
    "#verbs_nouns=nltk.pos_tag(tokens)\n",
    "#print(verbs_nouns)\n",
    "    \n",
    "#nltk.pos_tag(tokens)\n",
    "#training_data['Number_of_verbs']=0\n",
    "#training_data['Number_of_nouns']=0\n",
    "#training_data['Number_of_adjectives']=0\n",
    "\n",
    "\n",
    "#list=training_data['text'].tolist()[:2]\n",
    "#index=training_data.index[:2]\n",
    "\n",
    "#for text,location in zip(list,index):\n",
    " #   count_verbs=0\n",
    "  #  count_nouns=0\n",
    "   # count_adjectives=0\n",
    "    #nouns=[]\n",
    "    #verbs=[]\n",
    "    #adjectives=[]\n",
    "    #tokens=word_tokenize(text)\n",
    "    #tokens=nltk.pos_tag(tokens)\n",
    "    #print(tokens)\n",
    "    #for i in tokens:\n",
    "     #   \n",
    "      #  if(i[1].startswith('J')):\n",
    "       #     count_adjectives=count_adjectives+1\n",
    "        #    \n",
    "         #   print(\"count_adjectives\",' ',count_adjectives)\n",
    "          #  adjectives.append(1)\n",
    "        #if(i[1].startswith('V')):\n",
    "         #   count_verbs=count_verbs+1\n",
    "          #  print(\"count_Verbs\",' ',count_verbs)\n",
    "          #  verbs.append(1)\n",
    "       # if(i[1].startswith('N')):\n",
    "        #    count_nouns=count_nouns+1\n",
    "         #   print(\"count_Nouns\",' ',count_nouns)\n",
    "          #  #print(\"c\")\n",
    "           # verbs.append(1)\n",
    "        #if (i==tokens[-1]):\n",
    "         #   print(verbs)\n",
    "            #print(\"Inside count verbs\",' ',sum(verbs))\n",
    "            \n",
    "            #training_features.loc[location,\"Number_of_adjectives\"]=count_adjectives\n",
    "            #training_features.loc[location,\"Number_of_nouns\"]=count_nouns\n",
    "            #training_features.loc[location,\"Number_of_verbs\"]=sum(verbs)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            #nouns.append(count_nouns)\n",
    "    #print(adjectives[len(adjectives)-1])\n",
    "    \n",
    "    \n",
    "#training_data       \n",
    "\n",
    "#for i in index:\n",
    " #   print(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structured-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huhuh is a ,good boy?nsdkcsdk']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#d=training_data['text'][5]\n",
    "d='huhuh is a ,good boy?nsdkcsdk'\n",
    "print(nltk.sent_tokenize(d))\n",
    "print(len(nltk.sent_tokenize(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "impossible-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize=word_tokenize(d)\n",
    "#CorpusReader=nltk.corpus(d)\n",
    "#rint(len(CorpusReader.paras()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-guinea",
   "metadata": {},
   "source": [
    "## Making a new column for Cleaned text of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amended-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['Clean_words'] = validation_data['text'].apply(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exciting-output",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363ac6f16e232a1d8e9343d975ebe10</td>\n",
       "      <td>since communism has been relegated to just a h...</td>\n",
       "      <td>0</td>\n",
       "      <td>since communism has been relegated to just a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b925ce5eeb8b690b35972abafcb7c60</td>\n",
       "      <td>can you counter that?</td>\n",
       "      <td>0</td>\n",
       "      <td>can you counter that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99977c6e63734add1c1b600be79b3342</td>\n",
       "      <td>censorship does not eliminate the censored ind...</td>\n",
       "      <td>0</td>\n",
       "      <td>censorship does not eliminate the censored ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e34d9e198bc9e12f0868793c68d32f0</td>\n",
       "      <td>without the extra population from abortions, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>without the extra population from abortions  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629d09668c3339dba831f6c81a307b0e</td>\n",
       "      <td>i can't stand it</td>\n",
       "      <td>1</td>\n",
       "      <td>i can t stand it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>452684ca088e4ab1c58d89e1a28e1ef7</td>\n",
       "      <td>it's \"true\" or not and that \"truth\" is availab...</td>\n",
       "      <td>0</td>\n",
       "      <td>it s  true  or not and that  truth  is availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>b5fa34bde09f97ab565ec1ae433d1797</td>\n",
       "      <td>and these slogans don't even denote any sense ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and these slogans don t even denote any sense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>f676671baa396678dcb3471ea67e70ed</td>\n",
       "      <td>&amp;gt;whole-bodywhile</td>\n",
       "      <td>0</td>\n",
       "      <td>gt whole bodywhile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>a4e0fa2814bb40ae76750ea1597084de</td>\n",
       "      <td>that the majority of them are affected negativ...</td>\n",
       "      <td>1</td>\n",
       "      <td>that the majority of them are affected negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>5472aeb15e476c1542ca23ecd9c6e511</td>\n",
       "      <td>and just trying to be romantic with women, ass...</td>\n",
       "      <td>0</td>\n",
       "      <td>and just trying to be romantic with women  ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0     1363ac6f16e232a1d8e9343d975ebe10   \n",
       "1     6b925ce5eeb8b690b35972abafcb7c60   \n",
       "2     99977c6e63734add1c1b600be79b3342   \n",
       "3     7e34d9e198bc9e12f0868793c68d32f0   \n",
       "4     629d09668c3339dba831f6c81a307b0e   \n",
       "...                                ...   \n",
       "2614  452684ca088e4ab1c58d89e1a28e1ef7   \n",
       "2615  b5fa34bde09f97ab565ec1ae433d1797   \n",
       "2616  f676671baa396678dcb3471ea67e70ed   \n",
       "2617  a4e0fa2814bb40ae76750ea1597084de   \n",
       "2618  5472aeb15e476c1542ca23ecd9c6e511   \n",
       "\n",
       "                                                   text  label  \\\n",
       "0     since communism has been relegated to just a h...      0   \n",
       "1                                 can you counter that?      0   \n",
       "2     censorship does not eliminate the censored ind...      0   \n",
       "3     without the extra population from abortions, h...      0   \n",
       "4                                      i can't stand it      1   \n",
       "...                                                 ...    ...   \n",
       "2614  it's \"true\" or not and that \"truth\" is availab...      0   \n",
       "2615  and these slogans don't even denote any sense ...      0   \n",
       "2616                               &gt;whole-bodywhile       0   \n",
       "2617  that the majority of them are affected negativ...      1   \n",
       "2618  and just trying to be romantic with women, ass...      0   \n",
       "\n",
       "                                            Clean_words  \n",
       "0     since communism has been relegated to just a h...  \n",
       "1                                 can you counter that   \n",
       "2     censorship does not eliminate the censored ind...  \n",
       "3     without the extra population from abortions  h...  \n",
       "4                                      i can t stand it  \n",
       "...                                                 ...  \n",
       "2614  it s  true  or not and that  truth  is availab...  \n",
       "2615  and these slogans don t even denote any sense ...  \n",
       "2616                                 gt whole bodywhile  \n",
       "2617  that the majority of them are affected negativ...  \n",
       "2618  and just trying to be romantic with women  ass...  \n",
       "\n",
       "[2619 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aecfe3235c24d43c6f95ce59a16841c0</td>\n",
       "      <td>changing the us laws would not change internat...</td>\n",
       "      <td>1</td>\n",
       "      <td>changing the us laws would not change internat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02c28fbc7ae79544ed9ae2e232627dd5</td>\n",
       "      <td>there will always be evil people that bring mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>there will always be evil people that bring mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>059e6da466032dd7de62d60443b62d02</td>\n",
       "      <td>remember reasonable people actually voted hitl...</td>\n",
       "      <td>0</td>\n",
       "      <td>remember reasonable people actually voted hitl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6435772802042af0ee18a1b80ce727a7</td>\n",
       "      <td>, but did</td>\n",
       "      <td>0</td>\n",
       "      <td>but did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65595ce73b97078ef46c9d1dcb905a5c</td>\n",
       "      <td>, which</td>\n",
       "      <td>0</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>9614a90a4ab411f3765ec50befa9cef5</td>\n",
       "      <td>land before time has about 15 other movies in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>land before time has about 15 other movies in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>b49f77aa9914dbb7ae444b06472714c6</td>\n",
       "      <td>look around at classes.</td>\n",
       "      <td>0</td>\n",
       "      <td>look around at classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0cb29c202cfb23cebdfed2a62ccd2ba8</td>\n",
       "      <td>with absolutely anything, there will always be...</td>\n",
       "      <td>0</td>\n",
       "      <td>with absolutely anything  there will always be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>75b3e187dda4c59b0380bc7d1056dc20</td>\n",
       "      <td>perhaps my family (and quite a few other famil...</td>\n",
       "      <td>0</td>\n",
       "      <td>perhaps my family  and quite a few other famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>6b0f8503e4cd4b27ba34c8605226ec8a</td>\n",
       "      <td>'1.3.1.</td>\n",
       "      <td>0</td>\n",
       "      <td>1 3 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "0    aecfe3235c24d43c6f95ce59a16841c0   \n",
       "1    02c28fbc7ae79544ed9ae2e232627dd5   \n",
       "2    059e6da466032dd7de62d60443b62d02   \n",
       "3    6435772802042af0ee18a1b80ce727a7   \n",
       "4    65595ce73b97078ef46c9d1dcb905a5c   \n",
       "..                                ...   \n",
       "344  9614a90a4ab411f3765ec50befa9cef5   \n",
       "345  b49f77aa9914dbb7ae444b06472714c6   \n",
       "346  0cb29c202cfb23cebdfed2a62ccd2ba8   \n",
       "347  75b3e187dda4c59b0380bc7d1056dc20   \n",
       "348  6b0f8503e4cd4b27ba34c8605226ec8a   \n",
       "\n",
       "                                                  text  label  \\\n",
       "0    changing the us laws would not change internat...      1   \n",
       "1    there will always be evil people that bring mi...      1   \n",
       "2    remember reasonable people actually voted hitl...      0   \n",
       "3                                           , but did       0   \n",
       "4                                             , which       0   \n",
       "..                                                 ...    ...   \n",
       "344  land before time has about 15 other movies in ...      1   \n",
       "345                            look around at classes.      0   \n",
       "346  with absolutely anything, there will always be...      0   \n",
       "347  perhaps my family (and quite a few other famil...      0   \n",
       "348                                           '1.3.1.       0   \n",
       "\n",
       "                                           Clean_words  \n",
       "0    changing the us laws would not change internat...  \n",
       "1    there will always be evil people that bring mi...  \n",
       "2    remember reasonable people actually voted hitl...  \n",
       "3                                              but did  \n",
       "4                                                which  \n",
       "..                                                 ...  \n",
       "344  land before time has about 15 other movies in ...  \n",
       "345                            look around at classes   \n",
       "346  with absolutely anything  there will always be...  \n",
       "347  perhaps my family  and quite a few other famil...  \n",
       "348                                             1 3 1   \n",
       "\n",
       "[349 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_data)\n",
    "display(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-ticket",
   "metadata": {},
   "source": [
    "### Counterizing testing data and getting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quick-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'abortions', 'about', 'actually', 'after', 'all', 'also', 'always', 'am', 'an', 'and', 'and that', 'animals', 'any', 'are', 'argument', 'around', 'as', 'at', 'attention', 'bad', 'be', 'because', 'been', 'being', 'believe', 'best', 'better', 'but', 'by', 'can', 'change', 'cmv', 'could', 'country', 'did', 'didn', 'different', 'do', 'does', 'doesn', 'don', 'edit', 'enough', 'even', 'everyone', 'far', 'feel', 'few', 'find', 'first', 'for', 'for the', 'from', 'game', 'get', 'go', 'going', 'going to', 'good', 'gt', 'had', 'has', 'have', 'have been', 'have to', 'having', 'he', 'how', 'however', 'http', 'if', 'if you', 'in', 'in the', 'instead', 'intelligence', 'into', 'is', 'is the', 'isn', 'it', 'it is', 'its', 'just', 'know', 'less', 'life', 'like', 'likely', 'little', 'll', 'lot', 'lot of', 'made', 'make', 'makes', 'making', 'many', 'may', 'me', 'mean', 'meat', 'might', 'money', 'more', 'most', 'much', 'my', 'my view', 'need', 'never', 'no', 'not', 'now', 'of', 'of the', 'off', 'on', 'on the', 'one', 'only', 'or', 'other', 'our', 'out', 'over', 'own', 'people', 'person', 'point', 'post', 'probably', 'problem', 'put', 're', 'really', 'reason', 'relationship', 'religion', 'right', 'same', 'say', 'see', 'should', 'since', 'so', 'some', 'someone', 'something', 'still', 'such', 'take', 'than', 'that', 'that it', 'that the', 'that they', 'that you', 'the', 'the same', 'their', 'them', 'then', 'there', 'there is', 'these', 'they', 'they are', 'thing', 'things', 'think', 'this', 'this is', 'those', 'though', 'thought', 'time', 'to', 'to be', 'to do', 'to have', 'to make', 'to the', 'too', 'true', 'trying', 'understand', 'up', 'us', 've', 'very', 'view', 'want', 'want to', 'was', 'way', 'we', 'well', 'were', 'what', 'when', 'where', 'which', 'who', 'why', 'will', 'with', 'with the', 'without', 'world', 'would', 'would be', 'wrong', 'you', 'you are', 'you can', 'you have', 'you re', 'your']\n"
     ]
    }
   ],
   "source": [
    "#cv_counterized=TfidfVectorizer(max_features=50,ngram_range=(1,5))\n",
    "cv_counterized=CountVectorizer(max_features=220,ngram_range=(1,5))\n",
    "inputData_counterized_=cv_counterized.fit_transform(training_data['Clean_words'])\n",
    "print(cv_counterized.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-layout",
   "metadata": {},
   "source": [
    "### Preparing word embedings for training data  using CountVectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features=pd.DataFrame(inputData_counterized_.toarray(),columns=cv_counterized.get_feature_names())\n",
    "training_labels=np.array(training_data['label'])\n",
    "#training_features['Number_of_sentences']=training_data['text'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "#training_features['Word_count']=training_data['Clean_words'].apply(lambda x:len(x.split()))\n",
    "#training_features['Number_of_Characters']=training_data['Clean_words'].apply(lambda x:len(x.replace(\" \",\"\")))\n",
    "#X_counterized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-daisy",
   "metadata": {},
   "source": [
    "### Adding new Features for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caroline-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features['Number_of_sentences']=training_data['text'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "training_features['Word_count']=training_data['Clean_words'].apply(lambda x:len(x.split()))\n",
    "training_features['Number_of_Characters']=training_data['Clean_words'].apply(lambda x:len(x.replace(\" \",\"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-mount",
   "metadata": {},
   "source": [
    "### Intializing New Features for Training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "republican-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features['Number_of_adjectives']=0\n",
    "training_features['Number_of_nouns']=0\n",
    "training_features['Number_of_verbs']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-ordinary",
   "metadata": {},
   "source": [
    "### Function for adding new features in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expanded-lunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abortions</th>\n",
       "      <th>about</th>\n",
       "      <th>actually</th>\n",
       "      <th>after</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>you can</th>\n",
       "      <th>you have</th>\n",
       "      <th>you re</th>\n",
       "      <th>your</th>\n",
       "      <th>Number_of_sentences</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Number_of_Characters</th>\n",
       "      <th>Number_of_adjectives</th>\n",
       "      <th>Number_of_nouns</th>\n",
       "      <th>Number_of_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      able  abortions  about  actually  after  all  also  always  am  an  ...  \\\n",
       "0        0          0      0         0      0    0     0       0   0   0  ...   \n",
       "1        0          0      0         0      0    0     0       0   0   0  ...   \n",
       "2        0          0      0         0      0    0     0       0   0   0  ...   \n",
       "3        0          1      0         0      0    0     0       0   0   0  ...   \n",
       "4        0          0      0         0      0    0     0       0   0   0  ...   \n",
       "...    ...        ...    ...       ...    ...  ...   ...     ...  ..  ..  ...   \n",
       "2614     0          0      0         0      0    0     0       0   0   1  ...   \n",
       "2615     0          0      0         0      0    0     0       0   0   0  ...   \n",
       "2616     0          0      0         0      0    0     0       0   0   0  ...   \n",
       "2617     0          0      0         0      0    0     0       0   0   0  ...   \n",
       "2618     0          0      0         0      0    0     0       0   0   0  ...   \n",
       "\n",
       "      you can  you have  you re  your  Number_of_sentences  Word_count  \\\n",
       "0           0         0       0     0                    1          11   \n",
       "1           0         0       0     0                    1           4   \n",
       "2           0         0       0     0                    1           7   \n",
       "3           0         0       0     0                    1          39   \n",
       "4           0         0       0     0                    1           5   \n",
       "...       ...       ...     ...   ...                  ...         ...   \n",
       "2614        0         0       0     0                    1          16   \n",
       "2615        0         0       0     1                    1          22   \n",
       "2616        0         0       0     0                    1           3   \n",
       "2617        0         0       0     0                    1          12   \n",
       "2618        1         0       0     0                    1          31   \n",
       "\n",
       "      Number_of_Characters  Number_of_adjectives  Number_of_nouns  \\\n",
       "0                       55                     0                3   \n",
       "1                       17                     0                0   \n",
       "2                       47                     1                2   \n",
       "3                      197                     4               11   \n",
       "4                       12                     0                1   \n",
       "...                    ...                   ...              ...   \n",
       "2614                    54                     3                2   \n",
       "2615                   101                     2                6   \n",
       "2616                    16                     2                1   \n",
       "2617                    59                     0                2   \n",
       "2618                   146                     4                5   \n",
       "\n",
       "      Number_of_verbs  \n",
       "0                   3  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   6  \n",
       "4                   2  \n",
       "...               ...  \n",
       "2614                2  \n",
       "2615                2  \n",
       "2616                0  \n",
       "2617                3  \n",
       "2618                6  \n",
       "\n",
       "[2619 rows x 226 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#token=\"The tall and handsome guy\"\n",
    "#tokens=word_tokenize(token)\n",
    "#verbs_nouns=nltk.pos_tag(tokens)\n",
    "#counts=Counter(tag for word,tag in verbs_nouns)\n",
    "#type(counts)\n",
    "#for i in counts:\n",
    " #   print(type(i))\n",
    "  #  print(counts[i])\n",
    "    #print(i.values())\n",
    "#counts['DT']\n",
    "\n",
    "\n",
    "\n",
    "list=training_data['Clean_words']\n",
    "index=training_data.index\n",
    "for text,location in zip(list,index):\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=nltk.pos_tag(tokens)\n",
    "    #print(tokens)\n",
    "    counts=Counter(tag for word,tag in tokens)\n",
    "    #print(counts)\n",
    "    count_adjective=0\n",
    "    count_verbs=0\n",
    "    count_nouns=0\n",
    "    for i in counts:\n",
    "        if(i.startswith('J')):\n",
    "            adjective=counts[i]\n",
    "            count_adjective=count_adjective+adjective\n",
    "            \n",
    "        if(i.startswith('V')):\n",
    "            verb=counts[i]\n",
    "            count_verbs=count_verbs+verb\n",
    "            \n",
    "        if(i.startswith('N')):\n",
    "            noun=counts[i]\n",
    "            count_nouns=count_nouns+noun\n",
    "            \n",
    "    training_features.loc[location,\"Number_of_adjectives\"]=count_adjective\n",
    "    training_features.loc[location,'Number_of_verbs']=count_verbs\n",
    "    training_features.loc[location,'Number_of_nouns']=count_nouns\n",
    "            \n",
    "        \n",
    "            #verbs.append(counts[i])\n",
    "            #print('adjective is',sum(verbs))\n",
    "            \n",
    "    \n",
    "training_features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "american-consumer",
   "metadata": {},
   "source": [
    "### Counterizing Validaton data and preparing validation_features and validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alike-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>55</th>\n",
       "      <th>55 million</th>\n",
       "      <th>abortions</th>\n",
       "      <th>about</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>you can</th>\n",
       "      <th>you don</th>\n",
       "      <th>you re</th>\n",
       "      <th>your</th>\n",
       "      <th>Number_of_sentences</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Number_of_Characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     55  55 million  abortions  about  again  all  also  always  am  an  ...  \\\n",
       "0     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "1     0           0          0      0      0    0     0       1   0   0  ...   \n",
       "2     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "3     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "4     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "..   ..         ...        ...    ...    ...  ...   ...     ...  ..  ..  ...   \n",
       "344   0           0          0      1      0    0     0       0   0   0  ...   \n",
       "345   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "346   0           0          0      0      0    0     0       1   0   0  ...   \n",
       "347   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "348   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "\n",
       "     wrong  you  you are  you can  you don  you re  your  Number_of_sentences  \\\n",
       "0        0    0        0        0        0       0     0                    1   \n",
       "1        0    0        0        0        0       0     0                    1   \n",
       "2        0    0        0        0        0       0     0                    1   \n",
       "3        0    0        0        0        0       0     0                    1   \n",
       "4        0    0        0        0        0       0     0                    1   \n",
       "..     ...  ...      ...      ...      ...     ...   ...                  ...   \n",
       "344      0    0        0        0        0       0     0                    1   \n",
       "345      0    0        0        0        0       0     0                    1   \n",
       "346      0    0        0        0        0       0     0                    1   \n",
       "347      0    0        0        0        0       0     0                    1   \n",
       "348      0    0        0        0        0       0     0                    1   \n",
       "\n",
       "     Word_count  Number_of_Characters  \n",
       "0             9                    48  \n",
       "1            12                    52  \n",
       "2             8                    53  \n",
       "3             2                     6  \n",
       "4             1                     5  \n",
       "..          ...                   ...  \n",
       "344          19                    83  \n",
       "345           4                    19  \n",
       "346          16                    70  \n",
       "347          17                    72  \n",
       "348           3                     3  \n",
       "\n",
       "[349 rows x 223 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_counterized=cv_counterized.fit_transform(validation_data['Clean_words'])\n",
    "validation_features=pd.DataFrame(validation_counterized.toarray(),columns=cv_counterized.get_feature_names())\n",
    "Validation_labels=np.array(validation_data['label'])\n",
    "validation_features['Number_of_sentences']=validation_data['text'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "validation_features['Word_count']=validation_data['Clean_words'].apply(lambda x:len(x.split()))\n",
    "validation_features['Number_of_Characters']=validation_data['Clean_words'].apply(lambda x:len(x.replace(\" \",\"\")))\n",
    "\n",
    "validation_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-conflict",
   "metadata": {},
   "source": [
    "### Function for adding new features in Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "noble-parade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>55</th>\n",
       "      <th>55 million</th>\n",
       "      <th>abortions</th>\n",
       "      <th>about</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>you can</th>\n",
       "      <th>you don</th>\n",
       "      <th>you re</th>\n",
       "      <th>your</th>\n",
       "      <th>Number_of_sentences</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Number_of_Characters</th>\n",
       "      <th>Number_of_adjectives</th>\n",
       "      <th>Number_of_verbs</th>\n",
       "      <th>Number_of_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     55  55 million  abortions  about  again  all  also  always  am  an  ...  \\\n",
       "0     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "1     0           0          0      0      0    0     0       1   0   0  ...   \n",
       "2     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "3     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "4     0           0          0      0      0    0     0       0   0   0  ...   \n",
       "..   ..         ...        ...    ...    ...  ...   ...     ...  ..  ..  ...   \n",
       "344   0           0          0      1      0    0     0       0   0   0  ...   \n",
       "345   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "346   0           0          0      0      0    0     0       1   0   0  ...   \n",
       "347   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "348   0           0          0      0      0    0     0       0   0   0  ...   \n",
       "\n",
       "     you can  you don  you re  your  Number_of_sentences  Word_count  \\\n",
       "0          0        0       0     0                    1           9   \n",
       "1          0        0       0     0                    1          12   \n",
       "2          0        0       0     0                    1           8   \n",
       "3          0        0       0     0                    1           2   \n",
       "4          0        0       0     0                    1           1   \n",
       "..       ...      ...     ...   ...                  ...         ...   \n",
       "344        0        0       0     0                    1          19   \n",
       "345        0        0       0     0                    1           4   \n",
       "346        0        0       0     0                    1          16   \n",
       "347        0        0       0     0                    1          17   \n",
       "348        0        0       0     0                    1           3   \n",
       "\n",
       "     Number_of_Characters  Number_of_adjectives  Number_of_verbs  \\\n",
       "0                      48                   1.0              2.0   \n",
       "1                      52                   1.0              2.0   \n",
       "2                      53                   1.0              2.0   \n",
       "3                       6                   0.0              1.0   \n",
       "4                       5                   0.0              0.0   \n",
       "..                    ...                   ...              ...   \n",
       "344                    83                   2.0              2.0   \n",
       "345                    19                   0.0              0.0   \n",
       "346                    70                   0.0              3.0   \n",
       "347                    72                   2.0              3.0   \n",
       "348                     3                   0.0              0.0   \n",
       "\n",
       "     Number_of_nouns  \n",
       "0                2.0  \n",
       "1                3.0  \n",
       "2                3.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "..               ...  \n",
       "344              6.0  \n",
       "345              2.0  \n",
       "346              4.0  \n",
       "347              3.0  \n",
       "348              0.0  \n",
       "\n",
       "[349 rows x 226 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list=validation_data['Clean_words']\n",
    "index=validation_data.index\n",
    "for text,location in zip(list,index):\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=nltk.pos_tag(tokens)\n",
    "    #print(tokens)\n",
    "    counts=Counter(tag for word,tag in tokens)\n",
    "    #print(counts)\n",
    "    count_adjective=0\n",
    "    count_verbs=0\n",
    "    count_nouns=0\n",
    "    for i in counts:\n",
    "        if(i.startswith('J')):\n",
    "            adjective=counts[i]\n",
    "            count_adjective=count_adjective+adjective\n",
    "            \n",
    "        if(i.startswith('V')):\n",
    "            verb=counts[i]\n",
    "            count_verbs=count_verbs+verb\n",
    "            \n",
    "        if(i.startswith('N')):\n",
    "            noun=counts[i]\n",
    "            count_nouns=count_nouns+noun\n",
    "            \n",
    "    validation_features.loc[location,\"Number_of_adjectives\"]=count_adjective\n",
    "    validation_features.loc[location,'Number_of_verbs']=count_verbs\n",
    "    validation_features.loc[location,'Number_of_nouns']=count_nouns\n",
    "            \n",
    "        \n",
    "            #verbs.append(counts[i])\n",
    "            #print('adjective is',sum(verbs))\n",
    "            \n",
    "    \n",
    "validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-waterproof",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "optimum-functionality",
   "metadata": {},
   "source": [
    "### Feeding training_features and training labels to classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indoor-fashion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(C=15, kernel='poly', random_state=0))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test=train_test_split(X_counterized,Y_counterized,test_size=0.33, random_state=30)\n",
    "#C=0.5\n",
    "model=make_pipeline(StandardScaler(),SVC(kernel='poly',C=15,random_state=0))\n",
    "#model=LogisticRegression(solver='liblinear',random_state=0,C=15)\n",
    "#model=SVC(kernel='rbf',C=15,random_state=0)\n",
    "model.fit(training_features,training_labels)\n",
    "#x_predict=model.predict(training_features)\n",
    "#y_predict=model.predict(validation_features)\n",
    "#display(y_predict)\n",
    "#display(x_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-confidentiality",
   "metadata": {},
   "source": [
    "### Making prediction on validation with knowledge from trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "differential-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict=model.predict(validation_features)\n",
    "x_predict=model.predict(training_features)\n",
    "display(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executed-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-stanford",
   "metadata": {},
   "source": [
    "### Calculating the Precision, Recall and F1-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "northern-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.70      0.61       175\n",
      "           1       0.58      0.42      0.49       174\n",
      "\n",
      "    accuracy                           0.56       349\n",
      "   macro avg       0.56      0.56      0.55       349\n",
      "weighted avg       0.56      0.56      0.55       349\n",
      "\n",
      "[[122  53]\n",
      " [101  73]]\n",
      "0.5587392550143266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "print(classification_report(y_predict,Validation_labels))\n",
    "print(confusion_matrix(y_predict,Validation_labels))\n",
    "accuracy=metrics.accuracy_score(Validation_labels,y_predict) \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-crack",
   "metadata": {},
   "source": [
    "### Calculating F1-score for Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interpreted-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48666666666666664\n"
     ]
    }
   ],
   "source": [
    "f1_score=metrics.f1_score(Validation_labels,y_predict)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-safety",
   "metadata": {},
   "source": [
    "### Calculating F1-score for Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "certain-intention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8577023498694517\n"
     ]
    }
   ],
   "source": [
    "f1_score=metrics.f1_score(training_labels,x_predict)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-advertising",
   "metadata": {},
   "source": [
    "### Mapping ID's of validation data to the Predicted labels of validation using dictionary and exporting it to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "optional-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dictionary={}\n",
    "data=validation_data['id'].tolist()\n",
    "#predict=str(predict)\n",
    "#predict=list(predict)\n",
    "y_predict=[str(x) for x in y_predict]\n",
    "for id,label in zip(data,y_predict):\n",
    "    output_dictionary[id]=label\n",
    "#output_dict\n",
    "#print(type(predict))\n",
    "#print(predict[0])\n",
    "#output_dict.to_json('output.json')\n",
    "with open('output_file.json', 'w') as json_file:\n",
    "    json.dump(output_dictionary, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sustainable-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_data.iloc[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "entire-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "important-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_training=metrics.f1_score(training_labels,x_predict)\n",
    "#print(f1_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "proof-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dense-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29411765 0.27932961 0.25531915 0.29080119]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(model,training_features,training_labels,scoring='f1',cv=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-quantum",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "immediate-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esti ma\n",
    "\n",
    "#pipe = Pipeline([\n",
    " #       ('scale', StandardScaler()),\n",
    "  #      ('reduce_dims', PCA(n_components=4)),\n",
    "   #     ('clf', SVC(kernel = 'linear', C = 1))])\n",
    "\n",
    "#param_grid = dict(reduce_dims__n_components=[4,6,8],\n",
    " #                 clf__C=np.logspace(-4, 1, 6),\n",
    "  #                clf__kernel=['rbf','linear'])\n",
    "\n",
    "#grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=8, verbose=2)\n",
    "#grid.fit(training_features,training_labels)\n",
    "#x_predict=model.predict(training_features)\n",
    "#y_predict=model.predict(validation_features)\n",
    "#display(y_predict)\n",
    "#display(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "social-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score=metrics.f1_score(Validation_labels,y_predict)\n",
    "#print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "standing-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe=pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-verification",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-error",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-clock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-ecology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-chinese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-scheduling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
